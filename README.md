## Hi there ğŸ‘‹

I am an upcoming joint **PhD student** at **the State Key Laboratory of General Artificial Intelligence** <a href='https://www.bigai.ai/'>(BIGAI)</a> and **the University of Science and Technology of China** (USTC), supervised by <a href='https://liqing.io/'>Qing Li(BIGAI, æåº†)</a>, <a href='https://yuntaodu.github.io/'>Yuntao Du(SDU, æœäº‘æ¶›)</a>, <a href='https://siyuanqi.github.io/'>Siyuan Qi (Gyges Labs, ç¶¦æ€æº)</a> and <a href='http://staff.ustc.edu.cn/~binli/'>Bin Li (USTC, ææ–Œ)</a>, <a href='https://faculty.ustc.edu.cn/liulei13/zh_CN/index.htm'>Lei Liu (USTC, åˆ˜ç£Š)</a>. Currently, I am doing my internship in State Key Laboratory of General Artificial Intelligence.

I am currently working on knowledge editing, multimodal learning, continual learning.

My huggingface at ğŸ¤— [Huggingface home](https://huggingface.co/kailinjiang).

<!-- My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


# ğŸ”¥ News
<!-- Allowed emojis: ğŸ‰ğŸ‰for good news ğŸ“£ğŸ“£for average news-->
- **2025.03**: &nbsp;ğŸ‰ğŸ‰ One paper have been accepted by **ICLR 2025 Workshop SSI-FM**! <a href='https://mmke-bench-iclr.github.io/'>Multimodal Knowledge Editing</a>ï¼
- **2025.01**: &nbsp;ğŸ‰ğŸ‰ Two paper have been accepted by **ICLR 2025**! <a href='https://arxiv.org/pdf/2406.11194'>In Context Editing</a> and <a href='https://mmke-bench-iclr.github.io/'>Multimodal Knowledge Editing</a>ï¼
- **2024.06**: &nbsp;ğŸ‰ğŸ‰ I successfully completed my undergraduate studies from the College of Science of Sichuan Agricultural University!
- **2024.02**: &nbsp;ğŸ“£ğŸ“£ I will go to the State Key Laboratory of General Artificial Intelligence <a href='https://www.bigai.ai/'>(BIGAI)</a> to start my internship!

### ğŸ“ Homepages
- Personal Pages: ğŸŒ± [Personal Pages](https://kailinjiang.github.io/). (updated recentlyğŸ”¥)
- Google Scholar: ğŸ”­ [Google Scholar](https://scholar.google.com/citations?user=NSHQsrAAAAAJ&hl=zh-CN). 
- BIGAI Emailï¼šğŸ“«  jiangkailin@bigai.ai
- USTC Emailï¼šğŸ“«  kailinjiang@mail.ustc.edu.cn

# ğŸ“ Publications (First Author) 

- `ICLR2025 & ICLR2025 Workshop SSI-FM` [MMKE-Bench: A Multimodal Editing Benchmark for Diverse Visual Knowledge](https://arxiv.org/abs/2502.19870), Yuntao Du\*, **Kailin Jiang\***, Zhi Gao, Chenrui Shi, Zilong Zheng, Siyuan Qi, Qing Li. ã€2024.10ã€‘<br>

[![arXiv](https://img.shields.io/badge/Arxiv-2502.19870-b31b1b.svg?logo=arXiv)](https://arxiv.org/pdf/2502.19870) [![Dataset](https://img.shields.io/badge/%F0%9F%A4%97%20Dataset-MMKE_Bench-blue)](https://huggingface.co/datasets/kailinjiang/MMKE-Bench-dataset)  [![paperwithcode](https://img.shields.io/badge/PWC-MMKE_Bench-blue?logo=paperswithcode)](https://paperswithcode.com/paper/mmke-bench-a-multimodal-editing-benchmark-for)  [![code](https://img.shields.io/badge/Code-MMKE_Bench-blue?logo=github)](https://github.com/MMKE-Bench-ICLR/MMKE-Bench) [![website](https://img.shields.io/badge/Website-MMKE_Bench-orange?logo=homepage)](https://mmke-bench-iclr.github.io/) [![depositphotos](https://img.shields.io/badge/Poster-MMKE_Bench-red?logo=depositphotos)](./images/poster/iclr25_mmke_bench_poster.pdf)

[![airchina](https://img.shields.io/badge/æ•°æºAI-MMKE_Bench-red?logo=airchina)](https://mp.weixin.qq.com/s/iN826lITi5Xyz-3GnrdVIQ) [![codeproject](https://img.shields.io/badge/é‡å­ä¹‹å¿ƒ-MMKE_Bench-red?logo=codeproject)](https://www.xiaohongshu.com/explore/67e2d622000000000603cbfc?note_flow_source=wechat&xsec_token=CBldN8wUavDAzFvP4tK_noXO94RAXcelKKqlO3pFiJ6EQ=) [![actix](https://img.shields.io/badge/æå¸‚å¹³å°-MMKE_Bench-red?logo=actix)](https://mp.weixin.qq.com/s/JfxeytzWU0QoIUfJTGqgQQ) [![zhihu](https://img.shields.io/badge/çŸ¥ä¹-MMKE_Bench-red?logo=zhihu)](https://zhuanlan.zhihu.com/p/30599722521)



- `ICLR2025` [In-Context Editing: Learning Knowledge from Self-Induced Distributions](https://arxiv.org/pdf/2406.11194), Siyuan Qi\*, Bangcheng Yang\*, **Kailin Jiang\***, Xiaobo Wang, Jiaqi Li, Yifan Zhong, Yaodong Yang, Zilong Zheng. ã€2024.06ã€‘<br>

[![arXiv](https://img.shields.io/badge/Arxiv-2406.11194-b31b1b.svg?logo=arXiv)](https://arxiv.org/abs/2406.11194)  [![Dataset](https://img.shields.io/badge/%F0%9F%A4%97%20Dataset-ICE-blue)](https://huggingface.co/datasets/Yofuria/ICE)  [![paperwithcode](https://img.shields.io/badge/PWC-ICE-blue?logo=paperswithcode)](https://paperswithcode.com/paper/in-context-editing-learning-knowledge-from)  [![code](https://img.shields.io/badge/Code-ICE-blue?logo=github)](https://github.com/bigai-ai/ICE) [![depositphotos](https://img.shields.io/badge/Poster-ICE-red?logo=depositphotos)](./images/poster/ICE_poster.png)

[![AIModels.fyi](https://img.shields.io/badge/AIModels.fyi-ICE-blue?logo=anthropic)](https://www.aimodels.fyi/papers/arxiv/context-editing-learning-knowledge-from-self-induced) [![actix](https://img.shields.io/badge/æå¸‚å¹³å°-ICE-red?logo=actix)](https://mp.weixin.qq.com/s/Mr9HPeHJSsVfUIeF6j-zWw)





# ğŸ“ Publications (Other Author) 




# ğŸ“° Peer Review
- ICLR 2025 Workshop SSI-FM Reviewer



# ğŸ– Honors and Awards
- **2022.11** China Telecom Scholarship Â· Fly Young Award.
  
- **2021.11** National First Prize of Undergraduate Group of National Undergraduate Mathematical Modeling Contest of Gaojiaoshe Cup,team leader. 


# ğŸ“– Educations
- **2024.06 - now**, **University of Science and Technology of China (USTC), PhD student**. I am pursuing a degree in Information and Communication Engineering at USTC's School of Information Science and Technology, and the program is co-training with the State Key Laboratory of General Artificial Intelligence.

- **2020.09 - 2024.06**, **Sichuan Agricultural University (SICAU), graduate student**. I am studying for a degree in Information and Computational Science at the college of science in SICAU.


# ğŸ’» Internships
- **2024.02 - 2024.08**, <img src='./images/logo960.png' style='width: 6em;'> the State Key Laboratory of General Artificial Intelligence(Beijing,China), **MAS Lab**, Algorithm Intern.
- **2024.08 - now**, <img src='./images/logo960.png' style='width: 6em;'> the State Key Laboratory of General Artificial Intelligence(Beijing,China), **ML Lab**, Intern Researcher.




# ğŸ“Š GitHub Stats

![Kailin Jiang's GitHub Stats](https://github-readme-stats.vercel.app/api?username=kailinjiang&show_icons=true&theme=tokyonight)







<!--
**kailinjiang/kailinjiang** is a âœ¨ _special_ âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- ğŸ”­ Iâ€™m currently working on ...
- ğŸŒ± Iâ€™m currently learning ...
- ğŸ‘¯ Iâ€™m looking to collaborate on ...
- ğŸ¤” Iâ€™m looking for help with ...
- ğŸ’¬ Ask me about ...
- ğŸ“« How to reach me: ...
- ğŸ˜„ Pronouns: ...
- âš¡ Fun fact: ...
-->
